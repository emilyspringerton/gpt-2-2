name: GPT-2.2 Alpine CI

on:
  push:
    branches: [ "master", "main" ]
  pull_request:
    branches: [ "master", "main" ]

jobs:
  lean-build:
    runs-on: ubuntu-latest
    container: gcc:alpine
    
    steps:
    - uses: actions/checkout@v4

    # 1. Install Alpine-specific dependencies
    - name: Install System Libs (APK)
      run: |
        apk update
        apk add --no-cache libcurl curl-dev wget gcompat build-base

    # 2. Install LibTensorFlow (C API)
    - name: Install LibTensorFlow
      run: |
        wget -q https://storage.googleapis.com/tensorflow/libtensorflow/libtensorflow-cpu-linux-x86_64-1.15.0.tar.gz
        tar -C /usr/local -xzf libtensorflow-cpu-linux-x86_64-1.15.0.tar.gz
        # Alpine doesn't use ldconfig the same way, but /usr/local/lib is usually searched.

    # 3. Compile and Run Native Downloader (C + LibCURL)
    - name: Execute C-Downloader
      run: |
        gcc src/download_model.c -o download_model -lcurl
        ./download_model 124M

    # 4. Compile C Runtime Binding
    - name: Compile Native C Runtime
      run: |
        # We include -lgcompat to bridge the musl/glibc gap for libtensorflow
        gcc src/gpt2_run.c -o gpt2_run -I/usr/local/include -L/usr/local/lib -ltensorflow -lgcompat

    # 5. Verify
    - name: Proof of Loading
      run: |
        if [ -f "export/gpt2_124M_frozen.pb" ]; then
          ./gpt2_run export/gpt2_124M_frozen.pb
        else
          echo "Model logic compiled on Alpine. Protobuf artifact required for runtime."
        fi
